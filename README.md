Walkthrough: Appian Just-in-Time Knowledge Retrieval
I have completed the design and prototyping for the "Just-in-Time" knowledge retrieval system. This solution addresses the "Alt-Tab" problem by proactively pushing context-aware policy documents to agents directly within Appian.

Solution Architecture
The solution is composed of three main parts:

The Brain (Ingestion): Python script to chunk PDFs and store them with verifiable metadata.
The Bridge (Integration): Appian objects to query the Vector DB based on case context.
The Assistant (UI): A side-panel interface that displays results with deep links to specific pages.
Artifacts Created
Component	File	Description
Data Schema	vector_schema.md	Defines metadata for "Verifiable Citations" (pages, paragraphs).
Ingestion	knowledge_ingestion.py	Python script to ingest PDFs and upload to Vector DB.
Integration	Appian_Integration_Design.md	Design for Connected System & Integration Object.
User Interface	Appian_UI_Components.md	SAIL design for the "Knowledge Assistant" side panel.
Plan	implementation_plan.md	Initial technical plan.
Verification Results
Knowledge Ingestion Prototype
I ran the knowledge_ingestion.py script to simulate the ingestion of an "Auto Claims Policy".

Command: python knowledge_ingestion.py

Output:

Initialized Knowledge Engine for index: appian-knowledge
Loading document: Auto_Claims_Policy_v2.pdf
Created 4 chunks from document.
Upserting 4 vectors to Pinecone/Weaviate...
Upsert complete.
Interactive Demo (Streamlit)
I have created a local interactive prototype that simulates the Appian embedded experience.

Files Created:

simple_vector_store.py: Local RAG using sentence-transformers.
demo_app.py: Streamlit database dashboard.
How to Run:

Install dependencies: pip install streamlit sentence-transformers faiss-cpu
Run the app: python -m streamlit run demo_app.py
Open the URL (usually http://localhost:8501) to interact with the "Appian Knowledge Assistant".
